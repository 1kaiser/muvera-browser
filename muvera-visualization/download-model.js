// Model Download Script - Downloads EmbeddingGemma model for caching
import { AutoModel, AutoTokenizer } from '@xenova/transformers';

console.log('üöÄ Starting EmbeddingGemma model download...');
console.log('üì¶ Model: onnx-community/EmbeddingGemma-bge-small-ONNX (384D embeddings)');
console.log('‚ö†Ô∏è  This will download ~120MB - please wait...');

const startTime = Date.now();

async function downloadAndCacheModel() {
  try {
    console.log('üìù Step 1/2: Downloading tokenizer...');
    const tokenizer = await AutoTokenizer.from_pretrained('onnx-community/EmbeddingGemma-bge-small-ONNX', {
      progress_callback: (progress) => {
        if (progress.status === 'downloading') {
          const percent = (progress.loaded / progress.total * 100).toFixed(1);
          process.stdout.write(`\rüìù Tokenizer download: ${percent}%`);
        }
      }
    });
    console.log('\n‚úÖ Tokenizer downloaded and cached');

    console.log('üß† Step 2/2: Downloading model...');
    const model = await AutoModel.from_pretrained('onnx-community/EmbeddingGemma-bge-small-ONNX', {
      dtype: 'q8', // Quantized for smaller size
      progress_callback: (progress) => {
        if (progress.status === 'downloading') {
          const percent = (progress.loaded / progress.total * 100).toFixed(1);
          const mb = (progress.loaded / 1024 / 1024).toFixed(1);
          const totalMb = (progress.total / 1024 / 1024).toFixed(1);
          process.stdout.write(`\rüß† Model download: ${percent}% (${mb}/${totalMb} MB)`);
        }
      }
    });
    console.log('\n‚úÖ Model downloaded and cached');

    // Test the model works
    console.log('üîß Testing model functionality...');
    const testText = 'Hello world test embedding';
    
    const inputs = await tokenizer(testText, {
      return_tensors: 'pt',
      truncation: true,
      max_length: 512,
      padding: true
    });
    
    const outputs = await model(inputs);
    const embeddings = outputs.last_hidden_state;
    
    console.log('üîç Tensor shape:', embeddings.dims);
    console.log('üîç Available methods:', Object.getOwnPropertyNames(embeddings));
    
    // Manual mean pooling - more reliable
    const batchData = Array.from(embeddings.data);
    const seqLength = embeddings.dims[1];
    const hiddenSize = embeddings.dims[2];
    const embedding = new Array(hiddenSize).fill(0);
    
    // Average across sequence length (mean pooling)
    for (let i = 0; i < hiddenSize; i++) {
      let sum = 0;
      for (let j = 0; j < seqLength; j++) {
        sum += batchData[j * hiddenSize + i];
      }
      embedding[i] = sum / seqLength;
    }
    
    console.log(`‚úÖ Test successful! Generated ${embedding.length}D embedding`);
    console.log(`üìä First 5 values: [${embedding.slice(0, 5).map(v => v.toFixed(4)).join(', ')}...]`);
    
    const downloadTime = (Date.now() - startTime) / 1000;
    console.log(`‚è±Ô∏è  Total download time: ${downloadTime.toFixed(1)} seconds`);
    console.log('üéâ Model download complete! Tests can now run without timeout.');

  } catch (error) {
    console.error('‚ùå Download failed:', error.message);
    console.error('Full error:', error);
    process.exit(1);
  }
}

// Handle process termination gracefully
process.on('SIGINT', () => {
  console.log('\n‚ö†Ô∏è  Download interrupted by user');
  process.exit(0);
});

downloadAndCacheModel();